{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jTEzoMx6CasV"
   },
   "source": [
    "#### Copyright 2018 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IhmPj1VVCfWb"
   },
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ovTGnGws2vzf",
    "outputId": "62fd1378-f5a5-44c6-dc57-70dbf49ff60b"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YHK6DyunSbs4"
   },
   "source": [
    "# Cat vs. Dog Image Classification\n",
    "## Exercise 3: Feature Extraction and Fine-Tuning\n",
    "**_Estimated completion time: 30 minutes_**\n",
    "\n",
    "In Exercise 1, we built a convnet from scratch, and were able to achieve an accuracy of about 70%. With the addition of data augmentation and dropout in Exercise 2, we were able to increase accuracy to about 80%. That seems decent, but 20% is still too high of an error rate. Maybe we just don't have enough training data available to properly solve the problem. What other approaches can we try?\n",
    "\n",
    "In this exercise, we'll look at two techniques for repurposing feature data generated from image models that have already been trained on large sets of data, **feature extraction** and **fine tuning**, and use them to improve the accuracy of our cat vs. dog classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dI5rmt4UBwXs"
   },
   "source": [
    "## Feature Extraction Using a Pretrained Model\n",
    "\n",
    "One thing that is commonly done in computer vision is to take a model trained on a very large dataset, run it on your own, smaller dataset, and extract the intermediate representations (features) that the model generates. These representations are frequently informative for your own computer vision task, even though the task may be quite different from the problem that the original model was trained on. This versatility and repurposability of convnets is one of the most interesting aspects of deep learning.\n",
    "\n",
    "In our case, we will use the [Inception V3 model](https://arxiv.org/abs/1512.00567) developed at Google, and pre-trained on [ImageNet](http://image-net.org/), a large dataset of web images (1.4M images and 1000 classes). This is a powerful model; let's see what the features that it has learned can do for our cat vs. dog problem.\n",
    "\n",
    "First, we need to pick which intermediate layer of Inception V3 we will use for feature extraction. A common practice is to use the output of the very last layer before the `Flatten` operation, the so-called \"bottleneck layer.\" The reasoning here is that the following fully connected layers will be too specialized for the task the network was trained on, and thus the features learned by these layers won't be very useful for a new task. The bottleneck features, however, retain much generality.\n",
    "\n",
    "Let's instantiate an Inception V3 model preloaded with weights trained on ImageNet:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xJZ5glPPCRz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VaXLMtYiF0t9"
   },
   "source": [
    "Now let's download the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "KMrbllgAFipZ",
    "outputId": "32cb356d-b7b6-4905-cb99-89f9935d376f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-30 12:13:32--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 2a00:1450:400a:801::2010, 172.217.168.48\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2a00:1450:400a:801::2010|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 87910968 (84M) [application/x-hdf]\n",
      "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
      "\n",
      "/tmp/inception_v3_w 100%[===================>]  83.84M  5.36MB/s    in 16s     \n",
      "\n",
      "2020-04-30 12:13:49 (5.29 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
    "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UnRiGBfOF8rq"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "pre_trained_model = InceptionV3(\n",
    "    input_shape=(150, 150, 3), include_top=False, weights=None)\n",
    "pre_trained_model.load_weights(local_weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IcYZPBS3bTAj"
   },
   "source": [
    "By specifying the `include_top=False` argument, we load a network that doesn't include the classification layers at the top—ideal for feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CFxrqTuJee5m"
   },
   "source": [
    "Let's make the model non-trainable, since we will only use it for feature extraction; we won't update the weights of the pretrained model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a38rB3lyedcB"
   },
   "outputs": [],
   "source": [
    "for layer in pre_trained_model.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XGBGDiOAepnO"
   },
   "source": [
    "The layer we will use for feature extraction in Inception v3 is called `mixed7`. It is not the bottleneck of the network, but we are using it to keep a sufficiently large feature map (7x7 in this case). (Using the bottleneck layer would have resulting in a 3x3 feature map, which is a bit small.) Let's get the output from `mixed7`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Cj4rXshqbQlS",
    "outputId": "4c6f9ded-a7ef-4cd1-dce3-14658619f3e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape: (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape:', last_layer.output_shape)\n",
    "last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XxHk6XQLeUWh"
   },
   "source": [
    "Now let's stick a fully connected classifier on top of `last_output`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMXb913pbvFg"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Configure and compile the model\n",
    "model = Model(pre_trained_model.input, x)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.0001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_6ECjowwV5Ug"
   },
   "source": [
    "For examples and data preprocessing, let's use the same files and `train_generator` as we did in Exercise 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cl-IqOTjZVw_"
   },
   "source": [
    "**NOTE:** The 2,000 images used in this exercise are excerpted from the [\"Dogs vs. Cats\" dataset](https://www.kaggle.com/c/dogs-vs-cats/data) available on Kaggle, which contains 25,000 images. Here, we use a subset of the full dataset to decrease training time for educational purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "O4s8HckqGlnb",
    "outputId": "9f53ded1-90f5-42cb-8d98-7ebfcc4591d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-30 12:15:35--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 2a00:1450:400a:801::2010, 172.217.168.48\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|2a00:1450:400a:801::2010|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 68606236 (65M) [application/zip]\n",
      "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
      "\n",
      "/tmp/cats_and_dogs_ 100%[===================>]  65.43M  4.70MB/s    in 13s     \n",
      "\n",
      "2020-04-30 12:15:49 (5.04 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "   https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip -O \\\n",
    "   /tmp/cats_and_dogs_filtered.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Fl9XXARuV_eg",
    "outputId": "06ae7a9e-ef5e-4ee3-91bb-e5d637ab4082"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp')\n",
    "zip_ref.close()\n",
    "\n",
    "# Define our example directories and files\n",
    "base_dir = '/tmp/cats_and_dogs_filtered'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# Directory with our training cat pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "\n",
    "# Directory with our training dog pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "# Directory with our validation cat pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "\n",
    "# Directory with our validation dog pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "train_cat_fnames = os.listdir(train_cats_dir)\n",
    "train_dog_fnames = os.listdir(train_dogs_dir)\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir, # This is the source directory for training images\n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "# Flow validation images in batches of 20 using val_datagen generator\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qEC1AL7iVRLz"
   },
   "source": [
    "Finally, let's train the model using the features we extracted. We'll train on all 2000 images available, for 2 epochs, and validate on all 1,000 validation images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "colab_type": "code",
    "id": "Blhq2MAUeyGA",
    "outputId": "c65ba898-77e3-4ee1-e7d4-cb767c2cefc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 100 steps, validate for 50 steps\n",
      "Epoch 1/10\n",
      "100/100 - 88s - loss: 0.4951 - acc: 0.7650 - val_loss: 0.2563 - val_acc: 0.9110\n",
      "Epoch 2/10\n",
      "100/100 - 86s - loss: 0.3763 - acc: 0.8395 - val_loss: 0.2110 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      "100/100 - 86s - loss: 0.3542 - acc: 0.8485 - val_loss: 0.2890 - val_acc: 0.9370\n",
      "Epoch 4/10\n",
      "100/100 - 96s - loss: 0.3189 - acc: 0.8695 - val_loss: 0.5215 - val_acc: 0.9150\n",
      "Epoch 5/10\n",
      "100/100 - 90s - loss: 0.3149 - acc: 0.8690 - val_loss: 0.2238 - val_acc: 0.9610\n",
      "Epoch 6/10\n",
      "100/100 - 103s - loss: 0.3107 - acc: 0.8680 - val_loss: 0.3232 - val_acc: 0.9440\n",
      "Epoch 7/10\n",
      "100/100 - 95s - loss: 0.2856 - acc: 0.8875 - val_loss: 0.2259 - val_acc: 0.9640\n",
      "Epoch 8/10\n",
      "100/100 - 84s - loss: 0.2948 - acc: 0.8850 - val_loss: 0.4000 - val_acc: 0.9440\n",
      "Epoch 9/10\n",
      "100/100 - 95s - loss: 0.2615 - acc: 0.8905 - val_loss: 0.3530 - val_acc: 0.9490\n",
      "Epoch 10/10\n",
      "100/100 - 97s - loss: 0.2747 - acc: 0.8900 - val_loss: 0.4043 - val_acc: 0.9460\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=10,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "S8hwTr0e55BQ",
    "outputId": "3b5ab2ad-7f45-497b-c594-6cf625ac7ef3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 47,512,481\n",
      "Trainable params: 38,537,217\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Retrieve a list of accuracy results on training and validation data\n",
    "# sets for each training epoch\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "# Retrieve a list of list results on training and validation data\n",
    "# sets for each training epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Get number of epochs\n",
    "epochs = range(len(acc))\n",
    "\n",
    "# Plot training and validation accuracy per epoch\n",
    "plt.plot(epochs, acc)\n",
    "plt.plot(epochs, val_acc)\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Plot training and validation loss per epoch\n",
    "plt.plot(epochs, loss)\n",
    "plt.plot(epochs, val_loss)\n",
    "plt.title('Training and validation loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lRjyAkE62aOG"
   },
   "source": [
    "You can see that we reach a validation accuracy of 88–90% very quickly. This is much better than the small model we trained from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tt15y6IS2pBo"
   },
   "source": [
    "## Further Improving Accuracy with Fine-Tuning\n",
    "\n",
    "In our feature-extraction experiment, we only tried adding two classification layers on top of an Inception V3 layer. The weights of the pretrained network were not updated during training. One way to increase performance even further is to \"fine-tune\" the weights of the top layers of the pretrained model alongside the training of the top-level classifier. A couple of important notes on fine-tuning:\n",
    "\n",
    "- **Fine-tuning should only be attempted *after* you have trained the top-level classifier with the pretrained model set to non-trainable**. If you add a randomly initialized classifier on top of a pretrained model and attempt to train all layers jointly, the magnitude of the gradient updates will be too large (due to the random weights from the classifier), and your pretrained model will just forget everything it has learned.\n",
    "- Additionally, we **fine-tune only the *top layers* of the pre-trained model** rather than all layers of the pretrained model because, in a convnet, the higher up a layer is, the more specialized it is. The first few layers in a convnet learn very simple and generic features, which generalize to almost all types of images. But as you go higher up, the features are increasingly specific to the dataset that the model is trained on. The goal of fine-tuning is to adapt these specialized features to work with the new dataset.\n",
    "\n",
    "All we need to do to implement fine-tuning is to set the top layers of Inception V3 to be trainable, recompile the model (necessary for these changes to take effect), and resume training. Let's unfreeze all layers belonging to the `mixed7` module—i.e., all layers found after `mixed6`—and recompile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_l_J4S0Z2rgg"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "unfreeze = False\n",
    "\n",
    "# Unfreeze all models after \"mixed6\"\n",
    "for layer in pre_trained_model.layers:\n",
    "  if unfreeze:\n",
    "    layer.trainable = True\n",
    "  if layer.name == 'mixed6':\n",
    "    unfreeze = True\n",
    "\n",
    "# As an optimizer, here we will use SGD \n",
    "# with a very low learning rate (0.00001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=SGD(\n",
    "                  lr=0.00001, \n",
    "                  momentum=0.9),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE37ARlqY9da"
   },
   "source": [
    "Now let's retrain the model. We'll train on all 2000 images available, for 50 epochs, and validate on all 1,000 validation images. (This may take 15-20 minutes to run.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o_GgDGG4Y_hJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 100 steps, validate for 50 steps\n",
      "Epoch 1/50\n",
      "100/100 - 92s - loss: 0.2377 - acc: 0.8970 - val_loss: 0.5075 - val_acc: 0.9420\n",
      "Epoch 2/50\n",
      "100/100 - 80s - loss: 0.2489 - acc: 0.9015 - val_loss: 0.4887 - val_acc: 0.9460\n",
      "Epoch 3/50\n",
      "100/100 - 85s - loss: 0.2281 - acc: 0.9065 - val_loss: 0.4738 - val_acc: 0.9450\n",
      "Epoch 4/50\n",
      "100/100 - 85s - loss: 0.2359 - acc: 0.9045 - val_loss: 0.4714 - val_acc: 0.9460\n",
      "Epoch 5/50\n",
      "100/100 - 86s - loss: 0.2272 - acc: 0.9090 - val_loss: 0.4752 - val_acc: 0.9440\n",
      "Epoch 6/50\n",
      "100/100 - 82s - loss: 0.2037 - acc: 0.9155 - val_loss: 0.4736 - val_acc: 0.9450\n",
      "Epoch 7/50\n",
      "100/100 - 84s - loss: 0.2395 - acc: 0.9045 - val_loss: 0.4633 - val_acc: 0.9470\n",
      "Epoch 8/50\n",
      "100/100 - 83s - loss: 0.2195 - acc: 0.9025 - val_loss: 0.4624 - val_acc: 0.9470\n",
      "Epoch 9/50\n",
      "100/100 - 84s - loss: 0.2155 - acc: 0.9115 - val_loss: 0.4641 - val_acc: 0.9470\n",
      "Epoch 10/50\n",
      "100/100 - 90s - loss: 0.2202 - acc: 0.9030 - val_loss: 0.4657 - val_acc: 0.9460\n",
      "Epoch 11/50\n",
      "100/100 - 92s - loss: 0.2216 - acc: 0.9125 - val_loss: 0.4604 - val_acc: 0.9470\n",
      "Epoch 12/50\n",
      "100/100 - 82s - loss: 0.2155 - acc: 0.9070 - val_loss: 0.4536 - val_acc: 0.9470\n",
      "Epoch 13/50\n",
      "100/100 - 74s - loss: 0.1996 - acc: 0.9105 - val_loss: 0.4527 - val_acc: 0.9480\n",
      "Epoch 14/50\n",
      "100/100 - 75s - loss: 0.2242 - acc: 0.9110 - val_loss: 0.4450 - val_acc: 0.9470\n",
      "Epoch 15/50\n",
      "100/100 - 75s - loss: 0.2128 - acc: 0.9100 - val_loss: 0.4458 - val_acc: 0.9470\n",
      "Epoch 16/50\n",
      "100/100 - 74s - loss: 0.2155 - acc: 0.9060 - val_loss: 0.4406 - val_acc: 0.9470\n",
      "Epoch 17/50\n",
      "100/100 - 74s - loss: 0.2066 - acc: 0.9135 - val_loss: 0.4415 - val_acc: 0.9470\n",
      "Epoch 18/50\n",
      "100/100 - 75s - loss: 0.2151 - acc: 0.9135 - val_loss: 0.4370 - val_acc: 0.9470\n",
      "Epoch 19/50\n",
      "100/100 - 75s - loss: 0.1999 - acc: 0.9115 - val_loss: 0.4394 - val_acc: 0.9470\n",
      "Epoch 20/50\n",
      "100/100 - 74s - loss: 0.2130 - acc: 0.9125 - val_loss: 0.4299 - val_acc: 0.9470\n",
      "Epoch 21/50\n",
      "100/100 - 75s - loss: 0.2047 - acc: 0.9160 - val_loss: 0.4312 - val_acc: 0.9470\n",
      "Epoch 22/50\n",
      "100/100 - 75s - loss: 0.2136 - acc: 0.9080 - val_loss: 0.4344 - val_acc: 0.9470\n",
      "Epoch 23/50\n",
      "100/100 - 75s - loss: 0.2082 - acc: 0.9180 - val_loss: 0.4327 - val_acc: 0.9470\n",
      "Epoch 24/50\n",
      "100/100 - 74s - loss: 0.2212 - acc: 0.9140 - val_loss: 0.4269 - val_acc: 0.9470\n",
      "Epoch 25/50\n",
      "100/100 - 76s - loss: 0.1979 - acc: 0.9240 - val_loss: 0.4313 - val_acc: 0.9470\n",
      "Epoch 26/50\n",
      "100/100 - 76s - loss: 0.2291 - acc: 0.9040 - val_loss: 0.4334 - val_acc: 0.9470\n",
      "Epoch 27/50\n",
      "100/100 - 75s - loss: 0.2237 - acc: 0.9065 - val_loss: 0.4288 - val_acc: 0.9470\n",
      "Epoch 28/50\n",
      "100/100 - 75s - loss: 0.2113 - acc: 0.9110 - val_loss: 0.4239 - val_acc: 0.9470\n",
      "Epoch 29/50\n",
      "100/100 - 75s - loss: 0.2153 - acc: 0.9070 - val_loss: 0.4291 - val_acc: 0.9470\n",
      "Epoch 30/50\n",
      "100/100 - 75s - loss: 0.2033 - acc: 0.9185 - val_loss: 0.4268 - val_acc: 0.9470\n",
      "Epoch 31/50\n",
      "100/100 - 75s - loss: 0.2217 - acc: 0.9160 - val_loss: 0.4251 - val_acc: 0.9470\n",
      "Epoch 32/50\n",
      "100/100 - 74s - loss: 0.2229 - acc: 0.9000 - val_loss: 0.4206 - val_acc: 0.9470\n",
      "Epoch 33/50\n",
      "100/100 - 75s - loss: 0.2147 - acc: 0.9090 - val_loss: 0.4192 - val_acc: 0.9460\n",
      "Epoch 34/50\n",
      "100/100 - 76s - loss: 0.2017 - acc: 0.9190 - val_loss: 0.4258 - val_acc: 0.9470\n",
      "Epoch 35/50\n",
      "100/100 - 426s - loss: 0.2172 - acc: 0.9085 - val_loss: 0.4253 - val_acc: 0.9470\n",
      "Epoch 36/50\n",
      "100/100 - 80s - loss: 0.2152 - acc: 0.9050 - val_loss: 0.4225 - val_acc: 0.9470\n",
      "Epoch 37/50\n",
      "100/100 - 76s - loss: 0.2097 - acc: 0.9155 - val_loss: 0.4186 - val_acc: 0.9470\n",
      "Epoch 38/50\n",
      "100/100 - 78s - loss: 0.2063 - acc: 0.9130 - val_loss: 0.4176 - val_acc: 0.9460\n",
      "Epoch 39/50\n",
      "100/100 - 76s - loss: 0.2159 - acc: 0.9115 - val_loss: 0.4183 - val_acc: 0.9460\n",
      "Epoch 40/50\n",
      "100/100 - 81s - loss: 0.2058 - acc: 0.9150 - val_loss: 0.4180 - val_acc: 0.9460\n",
      "Epoch 41/50\n",
      "100/100 - 88s - loss: 0.2041 - acc: 0.9190 - val_loss: 0.4193 - val_acc: 0.9460\n",
      "Epoch 42/50\n",
      "100/100 - 75s - loss: 0.2063 - acc: 0.9110 - val_loss: 0.4218 - val_acc: 0.9460\n",
      "Epoch 43/50\n",
      "100/100 - 74s - loss: 0.2081 - acc: 0.9100 - val_loss: 0.4193 - val_acc: 0.9470\n",
      "Epoch 44/50\n",
      "100/100 - 74s - loss: 0.2165 - acc: 0.9115 - val_loss: 0.4194 - val_acc: 0.9470\n",
      "Epoch 45/50\n",
      "100/100 - 74s - loss: 0.2087 - acc: 0.9110 - val_loss: 0.4145 - val_acc: 0.9460\n",
      "Epoch 46/50\n",
      "100/100 - 75s - loss: 0.2134 - acc: 0.9025 - val_loss: 0.4192 - val_acc: 0.9460\n",
      "Epoch 47/50\n",
      "100/100 - 77s - loss: 0.2180 - acc: 0.9095 - val_loss: 0.4179 - val_acc: 0.9460\n",
      "Epoch 48/50\n",
      "100/100 - 79s - loss: 0.2150 - acc: 0.9070 - val_loss: 0.4184 - val_acc: 0.9460\n",
      "Epoch 49/50\n",
      "100/100 - 87s - loss: 0.2141 - acc: 0.9055 - val_loss: 0.4160 - val_acc: 0.9460\n",
      "Epoch 50/50\n",
      "100/100 - 88s - loss: 0.2250 - acc: 0.9055 - val_loss: 0.4125 - val_acc: 0.9460\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=50,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3EPGn58ofwq5"
   },
   "source": [
    "We are seeing a nice improvement, with the validation loss going from ~1.7 down to ~1.2, and accuracy going from 88% to 92%. That's a 4.5% relative improvement in accuracy.\n",
    "\n",
    "Let's plot the training and validation loss and accuracy to show it conclusively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1FtxcKjJfxL9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training and validation loss')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Retrieve a list of accuracy results on training and validation data\n",
    "# sets for each training epoch\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "# Retrieve a list of list results on training and validation data\n",
    "# sets for each training epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Get number of epochs\n",
    "epochs = range(len(acc))\n",
    "\n",
    "# Plot training and validation accuracy per epoch\n",
    "plt.plot(epochs, acc)\n",
    "plt.plot(epochs, val_acc)\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Plot training and validation loss per epoch\n",
    "plt.plot(epochs, loss)\n",
    "plt.plot(epochs, val_loss)\n",
    "plt.title('Training and validation loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X-fUIeizakjE"
   },
   "source": [
    "Congratulations! Using feature extraction and fine-tuning, you've built an image classification model that can identify cats vs. dogs in images with over 90% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x_ANwJCnx7w-"
   },
   "source": [
    "## Clean Up\n",
    "\n",
    "Run the following cell to terminate the kernel and free memory resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-hUmyohAyBzh"
   },
   "outputs": [],
   "source": [
    "import os, signal\n",
    "os.kill(os.getpid(), signal.SIGKILL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "03_cnn_template.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
