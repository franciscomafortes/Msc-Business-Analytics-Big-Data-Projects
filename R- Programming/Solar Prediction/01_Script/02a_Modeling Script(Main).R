folder_path <- "/Users/paula/Documents/IE IMBA/BIG DATA/Programming R/Group Assignment";
library(data.table);

solar <- readRDS(file.path(folder_path, "solar_dataset.RData"));
additional <- readRDS(file.path(folder_path, "additional_variables.RData"));
station_info <- fread(file.path(folder_path, "station_info.csv"));


############################### [PART 2] MODEL ##################################
############################### Summary ######################################
##There are three modelling strategies we have tried in predictive variable selections.
##[LM]
####[2.1.1]Select first 18 PCAs for each station
####[2.1.2]Select the most relevant 20 PCAs for each station
####[2.1.3]build new non-constant elevation train dataset with columns "date/station,PCA1-18,elevation" (In separate script file)
##[SVM]
####[2.2.1]SVM model with best hyperparameters for each station (selecting best hyperparameters on 10% of train data)
####[2.2.2]Clustering stations based on both distance and similar production level (The BEST model we chose)
#######Details:
#######Selecting best hyperparameters on 50% of train data
#######Production of clusters is calculated the average daily energy production generated by the stations within each cluster
##[2.3]Random Forest with first 18 PCAs


############################### [2.1] Linear Regression ##################################
############################### [2.1.1] First 18 PCAs ##################################
set.seed(100); 

ACME_2<-lm(ACME~ PC1+PC2+PC3+PC4+PC5+PC6+PC7+PC8+PC9+PC10+PC11+PC12+PC13+PC14
           +PC15+PC16+PC17+PC18, data=train_1)

predictions_ACME_test <- predict(ACME_2, newdata = test)
predictions_ACME_train<-predict(ACME_2, newdata = train_1)

errors_test <- predictions_ACME_test - test$ACME
errors_train<-predictions_ACME_train-train_1$ACME

mae_test<- round(mean(abs(errors_test)), 2);
mae_train<- round(mean(abs(errors_train)), 2);

mse_test<- round(mean(errors_test^2), 2);
mse_train<- round(mean(errors_train^2), 2);

############################### [2.1.2] Top 20 PCAs ##################################
################################## BUILD MODEL #######################################
set.seed(100);

solar$Year <- as.numeric(substr(solar$Date,1,4));
solar$Month <- as.numeric(substr(solar$Date,5,6));
solar$Day <- as.numeric(substr(solar$Date,7,8));

#### Separating populated energy values from NAs ##
predict <- solar[is.na(solar$ACME)];
big <- solar[!is.na(solar$ACME)];


#### Setting train/test split ##

train_index <- sample(1:nrow(big), 0.7*nrow(big));  
train <- big[train_index]; 
test  <- big[-train_index];


############################## SELECT IMPORTANT VARIABLES ####################################

install.packages("caret");
library(caret);

select_important<-function(dat, n_vars, y){
  varimp <- filterVarImp(x = dat, y=y, nonpara=TRUE);
  varimp <- data.table(variable=rownames(varimp),imp=varimp[, 1]);
  varimp <- varimp[order(-imp)];
  selected <- varimp$variable[1:n_vars];
  return(selected);
}


setDT(train);

comp <- data.table(model = "dummy", 
                   mse_train = "dummy", mae_train = "dummy",
                   mse_test = "dummy", mae_test = "dummy");
final <- predict[,1];

for (i in 2:99){
  print(i);
  
  train1 <- train[,..i];
  colnames(train1)[colnames(train1) %in% colnames(solar[,2:99])] <- "Production";
  train1 <- cbind(train1,train[,100:459]);
  important <- select_important(dat = train1[,2:ncol(train1)], n_vars = 20, y = unlist(c(train1[,1]),use.names=FALSE));
  print(important);
  
  f <- as.formula(paste(colnames(train1[,1]), 
                        paste(important, collapse = " + "), 
                        sep = " ~ "));
  
  model_train <- lm(f, data = train1);
  
  model_train;
  
  # Get model predictions
  predictions_train <- predict(model_train, newdata = train);
  predictions_test <- predict(model_train, newdata = test);
  
  # Get errors
  errors_train <- predictions_train - unlist(c(train[,..i]),use.names=FALSE);
  errors_test <- predictions_test - unlist(c(test[,..i]),use.names=FALSE);
  
  # Compute Metrics
  mse_train <- round(mean(errors_train^2), 2);
  mae_train <- round(mean(abs(errors_train)), 2);
  
  mse_test <- round(mean(errors_test^2), 2);
  mae_test <- round(mean(abs(errors_test)), 2);
  
  # Build comparison table
  comp <- rbind(comp,
                data.table(model = colnames(train[,..i]), 
                     mse_train = mse_train, mae_train = mae_train,
                     mse_test = mse_test, mae_test = mae_test));
  comp;
  
  # Create final predictions
  a <- predict(model_train, newdata = predict);
  final <- cbind(final,a);
  colnames(final)[colnames(final)=="a"] <- colnames(train[,..i]);

}



write.csv(final, "/Users/paula/Documents/IE IMBA/BIG DATA/Programming R/Group Assignment/final1312.csv",
          quote = F, row.names = F);


######################################## [2.2] TWO SVM Models (for each station, and for 5 CLUSTERS) ##################################


################################## BUILD MODEL #######################################
set.seed(100);

solar$Year <- as.numeric(substr(solar$Date,1,4));
solar$Month <- as.numeric(substr(solar$Date,5,6));
solar$Day <- as.numeric(substr(solar$Date,7,8));

#### Separating populated energy values from NAs ##
predict <- solar[is.na(solar$ACME)];
big <- solar[!is.na(solar$ACME)];


#### Setting train/test split ##
train_index <- sample(1:nrow(big), 0.7*nrow(big));  
train <- big[train_index]; 
test  <- big[-train_index];


######################################## [2.2.1]SVM USING BEST HYPERPARAMETERS FOR EACH STATION #########################################
#install.packages("e1071");
library(e1071); # LIBSVM
library(foreach);

set.seed(100); 

train_index <- sample(1:nrow(big), 0.7*nrow(big));  
val_index <- sample(setdiff(1:nrow(big), train_index), 0.15*nrow(big));  
test_index <- setdiff(1:nrow(big), c(train_index, val_index));

train <- big[train_index]; 
val <- big[val_index]; 
test  <- big[test_index];

### Define grid
c_values <- 10^seq(from = -3, to = 3, by = 1);
eps_values <- 10^seq(from = -3, to = 0, by = 1);
gamma_values <- 10^seq(from = -3, to = 3, by = 1);

### Compute grid search
grid_results <- data.table();

comp_svm <- data.table();
final_svm <- predict[,1];


for (i in 2:99){
  
  print(i);
  
  train1 <- train[,..i];
  colnames(train1)[colnames(train1) %in% colnames(solar[,2:99])] <- "Production";
  train1 <- cbind(train1,train[,100:459]);
  
  val1 <- val[,..i];
  colnames(val1)[colnames(val1) %in% colnames(solar[,2:99])] <- "Production";
  val1 <- cbind(val1,val[,100:459]);
  
  foreach (c = c_values)%:%
    foreach (eps = eps_values)%:%
    foreach (gamma = gamma_values)%dopar%{
      
      print(sprintf("Start of c = %s - eps = %s - gamma = %s", c, eps, gamma));
      
      f <- as.formula(paste(colnames(train1[,1]), ".", sep = " ~ "));
      
      # train SVM model with a particular set of hyperparameters on 20% of train data
      train_hp_index <- sample(1:nrow(train1), 0.2*nrow(train1));  
      train_hp <- train1[train_hp_index]; 
      model_svm <- svm(f, data = train_hp,
                       cost = c, epsilon = eps, gamma = gamma);
      
      
      # Get model predictions
      predictions_train <- predict(model_svm, newdata = train);
      predictions_val <- predict(model_svm, newdata = val);
      
      # Get errors
      errors_train <- predictions_train - unlist(c(train[,..i]),use.names=FALSE);
      errors_val <- predictions_val - unlist(c(val[,..i]),use.names=FALSE);
      
      # Compute Metrics
      mse_train <- round(mean(errors_train^2), 2);
      mae_train <- round(mean(abs(errors_train)), 2);
      
      mse_val <- round(mean(errors_val^2), 2);
      mae_val <- round(mean(abs(errors_val)), 2);
      
      # Build comparison table
      grid_results <- rbind(grid_results,
                            data.table(c = c, eps = eps, gamma = gamma, 
                                       mse_train = mse_train, mae_train = mae_train,
                                       mse_val = mse_val, mae_val = mae_val));
    }
  
  
  
  # Order results by increasing mse and mae
  grid_results <- grid_results[order(mse_val, mae_val)];
  
  # Best hyperparameters
  best <- grid_results[1];
  
  # train SVM model with best found set of hyperparamets
  model_svm <- svm(f, data = rbind(train1,val1), 
                   cost = best$c, epsilon = best$eps, gamma = best$gamma);
  
  
  # Get model predictions
  predictions_train <- predict(model_svm, newdata = train);
  predictions_val <- predict(model_svm, newdata = val);
  predictions_test <- predict(model_svm, newdata = test);
  
  # Get errors
  errors_train <- predictions_train - unlist(c(train[,..i]),use.names=FALSE);
  errors_val <- predictions_val - unlist(c(val[,..i]),use.names=FALSE);
  errors_test <- predictions_test - unlist(c(test[,..i]),use.names=FALSE);
  
  # Compute Metrics
  mse_train <- round(mean(errors_train^2), 2);
  mae_train <- round(mean(abs(errors_train)), 2);
  
  mse_val <- round(mean(errors_val^2), 2);
  mae_val <- round(mean(abs(errors_val)), 2);
  
  mse_test <- round(mean(errors_test^2), 2);
  mae_test <- round(mean(abs(errors_test)), 2);
  
  
  # Build comparison table
  comp_svm <- rbind(comp_svm,
                    data.table(model = colnames(train[,..i]), 
                               mse_train = mse_train, mae_train = mae_train,
                               mse_test = mse_test, mae_test = mae_test));
  comp_svm;
  
  # Create final predictions
  predict1 <- predict[,100:459];
  a <- predict(model_svm, newdata = predict1);
  final_svm <- cbind(final_svm,a);
  colnames(final_svm)[colnames(final_svm)=="a"] <- colnames(train[,..i]);
  
}


write.csv(final_svm, "/Users/paula/Documents/IE IMBA/BIG DATA/Programming R/Group Assignment/final_svm1412.csv",
          quote = F, row.names = F);

write.csv(comp_svm, "/Users/paula/Documents/IE IMBA/BIG DATA/Programming R/Group Assignment/comp_svm1412.csv",
          quote = F, row.names = F);







################################# [2.2.2]SVM USING BEST HYPERPARAMETERS BY CLUSTER (5 CLUSTERS) ###########################################

#install.packages("e1071");
library(e1071); # LIBSVM
library(foreach);

set.seed(100); 

train_index <- sample(1:nrow(big), 0.7*nrow(big));  
val_index <- sample(setdiff(1:nrow(big), train_index), 0.15*nrow(big));  
test_index <- setdiff(1:nrow(big), c(train_index, val_index));

train <- big[train_index]; 
val <- big[val_index]; 
test  <- big[test_index];

### Define grid
c_values <- 10^seq(from = -3, to = 3, by = 1);
eps_values <- 10^seq(from = -3, to = 0, by = 1);
gamma_values <- 10^seq(from = -3, to = 3, by = 1);



CL1_names <- c("BOIS","KENT","GOOD","HOOK");
CL2_names <- c("ARNE","BESS","BUTL","WEAT","CHEY","ERIC","CAMA","PUTN","SEIL","HOBA","RETR","CHER","FAIR",
               "LAHO","FREE","MAYR","BEAV","SLAP","BUFF","WOOD");
CL3_names <- c("IDAB","DURA");
CL4_names <- c("WAUR","RING","MADI","BURN","TIPT","MANG","ALTU","HOLL","MINC","ELRE","STIL","PERK","MARE","SPEN","GUTH","WATO",
               "WASH","PAUL","SULP","CENT","BYAR","ADAX","TISH","BOWL","HINT","FTCB","NINN","CHIC","KETC","APAC","ACME","MEDI");
CL5_names <- c("SHAW","CHAN","TAHL","SALL","COOK","WEST","STIG","NOWA","COPA","VINI","MIAM","PRYO","JAYX","WILB","TALI","CLAY",
               "STUA","MCAL","MTHE","HUGO","CLOU","WIST","LANE","WYNO","SKIA","OKMU","EUFA","OKEM","OILT","BRIS","HASK","BIXB",
               "PAWN","NEWK","BURB","REDR","MEDF","FORA","BREC","BLAC");


CL1_train <- as.data.table(rowMeans(train[,..CL1_names]));
colnames(CL1_train)[colnames(CL1_train) == "V1"] <- "Production_CL1";

CL2_train <- as.data.table(rowMeans(train[,..CL2_names]));
colnames(CL2_train)[colnames(CL2_train) == "V1"] <- "Production_CL2";
cluster_train <- cbind(CL1_train,CL2_train);

CL3_train <- as.data.table(rowMeans(train[,..CL3_names]));
colnames(CL3_train)[colnames(CL3_train) == "V1"] <- "Production_CL3";
cluster_train <- cbind(cluster_train,CL3_train);

CL4_train <- as.data.table(rowMeans(train[,..CL4_names]));
colnames(CL4_train)[colnames(CL4_train) == "V1"] <- "Production_CL4";
cluster_train <- cbind(cluster_train,CL4_train);

CL5_train <- as.data.table(rowMeans(train[,..CL5_names]));
colnames(CL5_train)[colnames(CL5_train) == "V1"] <- "Production_CL5";
cluster_train <- cbind(cluster_train,CL5_train);



CL1_val <- as.data.table(rowMeans(val[,..CL1_names]));
colnames(CL1_val)[colnames(CL1_val) == "V1"] <- "Production_CL1";

CL2_val <- as.data.table(rowMeans(val[,..CL2_names]));
colnames(CL2_val)[colnames(CL2_val) == "V1"] <- "Production_CL2";
cluster_val <- cbind(CL1_val,CL2_val);

CL3_val <- as.data.table(rowMeans(val[,..CL3_names]));
colnames(CL3_val)[colnames(CL3_val) == "V1"] <- "Production_CL3";
cluster_val <- cbind(cluster_val,CL3_val);

CL4_val <- as.data.table(rowMeans(val[,..CL4_names]));
colnames(CL4_val)[colnames(CL4_val) == "V1"] <- "Production_CL4";
cluster_val <- cbind(cluster_val,CL4_val);

CL5_val <- as.data.table(rowMeans(val[,..CL5_names]));
colnames(CL5_val)[colnames(CL5_val) == "V1"] <- "Production_CL5";
cluster_val <- cbind(cluster_val,CL5_val);



best <- data.table();

for (i in 1:5){
  
  print(i);
  grid_results <- data.table();
  
  foreach (c = c_values)%:%
    foreach (eps = eps_values)%:%
    foreach (gamma = gamma_values)%dopar%{
      
      print(sprintf("Start of c = %s - eps = %s - gamma = %s", c, eps, gamma));
      
      train1 <- cluster_train[,..i];
      colnames(train1)[colnames(train1) == paste("Production_CL",i, sep = "")] <- "Production";
      train1 <- cbind(train1,train[,100:459]);
      
      val1 <- cluster_val[,..i];
      colnames(val1)[colnames(val1) == paste("Production_CL",i, sep = "")] <- "Production";
      val1 <- cbind(val1,val[,100:459]);
      
      f <- as.formula(paste(colnames(train1[,1]), ".", sep = " ~ "));
      
      # train SVM model with a particular set of hyperparameters on 50% of train data
      train_hp_index <- sample(1:nrow(train1), 0.5*nrow(train1));  
      train_hp <- train1[train_hp_index]; 
      model_svm <- svm(f, data = train_hp,
                       cost = c, epsilon = eps, gamma = gamma);
      
      # Get model predictions
      predictions_train <- predict(model_svm, newdata = train);
      predictions_val <- predict(model_svm, newdata = val);
      
      # Get errors
      errors_train <- predictions_train - unlist(c(train1[,1]),use.names=FALSE);
      errors_val <- predictions_val - unlist(c(val1[,1]),use.names=FALSE);
      
      # Compute Metrics
      mse_train <- round(mean(errors_train^2), 2);
      mae_train <- round(mean(abs(errors_train)), 2);
      
      mse_val <- round(mean(errors_val^2), 2);
      mae_val <- round(mean(abs(errors_val)), 2);
      
      # Build comparison table
      grid_results <- rbind(grid_results,
                            data.table(cluster = paste("cl",i, sep = ""),
                                       c = c, eps = eps, gamma = gamma, 
                                       mse_train = mse_train, mae_train = mae_train,
                                       mse_val = mse_val, mae_val = mae_val));
    }
  
  
  # Order results by increasing mse and mae
  grid_results <- grid_results[order(mse_val, mae_val)];
  
  # Best hyperparameters
  best <- rbind(best, grid_results[1]);
}


write.csv(best, "/Users/paula/Documents/IE IMBA/BIG DATA/Programming R/Group Assignment/best_hp_clusters1412.csv",
          quote = F, row.names = F);


comp_svm <- data.table();
final_svm <- predict[,1];


for (i in 2:99){
  
  print(i);
  
  if (colnames(train[,..i]) %in% CL1_names){
    cluster <- "cl1"} else if (colnames(train[,..i]) %in% CL2_names){
      cluster <- "cl2"} else if (colnames(train[,..i]) %in% CL3_names){
        cluster <- "cl3"} else if (colnames(train[,..i]) %in% CL4_names){
          cluster <- "cl4"} else {cluster <- "cl5"};
  
  train1 <- train[,..i];
  colnames(train1)[colnames(train1) %in% colnames(solar[,2:99])] <- "Production";
  train1 <- cbind(train1,train[,100:459]);
  
  val1 <- val[,..i];
  colnames(val1)[colnames(val1) %in% colnames(solar[,2:99])] <- "Production";
  val1 <- cbind(val1,val[,100:459]);
  
  
  # train SVM model with best found set of hyperparamets
  model_svm <- svm(f, data = rbind(train1,val1), 
                   cost = best$c[best$cluster == cluster], 
                   epsilon = best$eps[best$cluster == cluster], 
                   gamma = best$gamma[best$cluster == cluster]);
  
  
  # Get model predictions
  predictions_train <- predict(model_svm, newdata = train);
  predictions_val <- predict(model_svm, newdata = val);
  predictions_test <- predict(model_svm, newdata = test);
  
  # Get errors
  errors_train <- predictions_train - unlist(c(train[,..i]),use.names=FALSE);
  errors_val <- predictions_val - unlist(c(val[,..i]),use.names=FALSE);
  errors_test <- predictions_test - unlist(c(test[,..i]),use.names=FALSE);
  
  # Compute Metrics
  mse_train <- round(mean(errors_train^2), 2);
  mae_train <- round(mean(abs(errors_train)), 2);
  
  mse_val <- round(mean(errors_val^2), 2);
  mae_val <- round(mean(abs(errors_val)), 2);
  
  mse_test <- round(mean(errors_test^2), 2);
  mae_test <- round(mean(abs(errors_test)), 2);
  
  
  # Build comparison table
  comp_svm <- rbind(comp_svm,
                    data.table(model = colnames(train[,..i]), 
                               mse_train = mse_train, mae_train = mae_train,
                               mse_test = mse_test, mae_test = mae_test));
  comp_svm;
  
  # Create final predictions
  predict1 <- predict[,100:459];
  a <- predict(model_svm, newdata = predict1);
  final_svm <- cbind(final_svm,a);
  colnames(final_svm)[colnames(final_svm)=="a"] <- colnames(train[,..i]);
  
}



write.csv(final_svm, "/Users/paula/Documents/IE IMBA/BIG DATA/Programming R/Group Assignment/final_cluster_svm1512.csv",
          quote = F, row.names = F);

write.csv(comp_svm, "/Users/paula/Documents/IE IMBA/BIG DATA/Programming R/Group Assignment/comp_cluster_svm1512.csv",
          quote = F, row.names = F);


###################################### [2.3] Random Forest#########################################
install.packages("randomForest")
library(randomForest);
ACME_5<-randomForest(ACME ~PC1+PC2+PC3+PC4+PC5+PC6+PC7+PC8+PC9+PC10+PC11+PC12+PC13+PC14
                     +PC15+PC16+PC17+PC18, train_1,importance=T,proximity=T)

ptrain_rf_1 <- predict(ACME_5, newdata = train_1);
ptest_rf_1 <- predict(ACME_5, newdata = test);

errors_train_4 <- ptrain_rf_1 - train_1$ACME;
errors_test_4<- ptest_rf_1 - test$ACME;

mse_train_4 <- round(mean(errors_train_4^2), 2);
mae_train_4 <- round(mean(abs(errors_train_4)), 2);
mse_test_4<- round(mean(errors_test_4^2), 2);
mae_test_4 <- round(mean(abs(errors_test_4)), 2);


